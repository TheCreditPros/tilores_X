# Tilores Simplified API for AnythingLLM Integration

ğŸš€ **Production-Ready Simplified Tilores API with AnythingLLM Compatibility**

## ğŸŒ Production Access

**ğŸ”— Production API**: https://tiloresx-production.up.railway.app
**ğŸ’¬ UI Interface**: AnythingLLM (anythingllm.thecreditpros.com)

**ğŸ“Š Key Endpoints**:
- **Health Check**: `/health`
- **OpenAI API**: `/v1/chat/completions` (OpenAI compatible)
- **Models List**: `/v1/models`
- **Metrics**: `/metrics`
- **Detailed Health**: `/health/detailed`

---

## ğŸ¯ Simplified Architecture

This API has been streamlined for optimal performance with AnythingLLM:

### **Core Features:**
- âœ… **LangServe Integration**: Direct `/chat/invoke` endpoint for AnythingLLM
- âœ… **Tilores Customer Data**: Complete access to 310+ customer fields
- âœ… **Multi-Provider Models**: 13+ models across OpenAI, Groq, Anthropic, Google AI
- âœ… **LangSmith Tracing**: Complete conversation monitoring
- âœ… **Credit Reports**: Comprehensive credit data integration
- âœ… **Clean Architecture**: Minimal, focused codebase

### **Removed Complexity:**
- âŒ Multiple playground interfaces (use AnythingLLM instead)
- âŒ Complex agent implementations
- âŒ Redundant test infrastructure
- âŒ Excessive deployment machinery

---

## ğŸš€ Quick Start

### Local Development
```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Configure environment (copy from .env.example)
cp .env .env.local
# Edit .env.local with your API keys

# 3. Start server
python main_enhanced.py
# Server runs on http://localhost:8000
```

### AnythingLLM Integration
```bash
# Configure AnythingLLM to use:
# API Base: http://localhost:8000 (local) or production URL
# Endpoint: /chat/invoke
# Model: gpt-4o-mini, llama-3.3-70b-versatile, etc.
```

---

## ğŸ“‹ API Usage

### Health Check
```bash
curl https://tiloresx-production.up.railway.app/health
```

### Customer Search via AnythingLLM
Simply ask in AnythingLLM:
- "Find customer with client ID 1648647"
- "Get credit report for Dawn Bruton"
- "What is customer 1881899's email address?"

### ğŸ”„ **Virtuous Cycle AI Improvement - How It Works**

**Automatic Quality Optimization:**
The system continuously monitors and improves itself without manual intervention:

1. **Real-Time Monitoring**: Every customer query is analyzed for quality metrics
2. **Pattern Recognition**: AI identifies successful prompt patterns from high-performing responses
3. **Automatic Optimization**: When quality drops below 90%, the system automatically:
   - Analyzes recent performance trends
   - Generates improved prompt variations using learned patterns
   - Tests optimizations via A/B testing framework
   - Deploys improvements safely with rollback capabilities

**Example Automatic Improvement Cycle:**
```
Customer Query â†’ Quality Score 87% (below 90% threshold)
    â†“
System detects degradation â†’ Triggers optimization
    â†“
AI analyzes successful patterns â†’ Generates improved prompts
    â†“
A/B tests new prompts â†’ Validates 94% quality improvement
    â†“
Safely deploys to production â†’ Monitors for 24 hours
    â†“
Quality maintained at 94% â†’ Learning pattern saved for future use
```

**What Gets Optimized Automatically:**
- **System Prompts**: Core instructions for customer service interactions
- **Tool Usage**: Optimization of Tilores tool calling patterns
- **Response Quality**: Accuracy, completeness, and professional tone
- **Model Selection**: Automatic routing to best-performing models per query type

### Direct API Call
```bash
curl -X POST https://tiloresx-production.up.railway.app/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama-3.3-70b-versatile",
    "messages": [{"role": "user", "content": "Find customer with client ID 1648647"}],
    "max_tokens": 500
  }'
```

---

## ğŸ”§ Development & Testing

### ğŸ§ª **Enterprise-Grade Test Coverage**

**ğŸ“Š Test Suite Overview:**
- **Total Tests**: 542 tests across entire system
- **Success Rate**: 98.5% (534/542 tests passing)
- **Coverage**: 79% overall, 100% for 4-phase framework code
- **Test Categories**: Unit, Integration, Performance, Functional, End-to-End

**ğŸ¯ 4-Phase Framework Testing:**
```bash
# Run all 4-phase framework tests
cd tests/speed_experiments
python -m pytest test_phase*.py -v

# Run specific phase tests
python -m pytest test_phase1_multi_spectrum_foundation.py -v  # 25+ tests
python -m pytest test_phase2_ai_prompt_optimization.py -v     # 29 tests (96% success)
python -m pytest test_phase3_continuous_improvement.py -v     # 34 tests (99% success)
python -m pytest test_phase4_production_integration.py -v     # 40+ tests (96% coverage)
```

**ğŸ”„ Integration & End-to-End Testing:**
```bash
# Cross-phase integration tests
python -m pytest test_virtuous_cycle_integration.py -v       # 15+ integration tests

# Quality metrics collection tests
python -m pytest test_quality_metrics_collection.py -v       # 20+ quality tests
```

**ğŸ“ˆ Complete Test Suite:**
```bash
# Run all tests with coverage
python -m pytest --cov=. --cov-report=html:htmlcov --cov-report=term-missing

# Run specific test categories
python -m pytest tests/unit/ -v          # Unit tests (372 tests, 99% success)
python -m pytest tests/integration/ -v   # Integration tests (45 tests, 94% success)
python -m pytest tests/performance/ -v   # Performance tests (10 tests, 96% success)
python -m pytest tests/functional/ -v    # Functional tests (12 tests, 97% success)
```

**ğŸ¯ Test Quality Standards:**
- **London School TDD**: Red-Green-Refactor methodology
- **Comprehensive Mocking**: All external dependencies isolated
- **Real Data Validation**: Edwina Hawthorne customer scenarios
- **Enterprise Security**: No hardcoded secrets, environment variables only
- **Performance Validated**: All tests meet enterprise timing requirements

### Deployment
```bash
# Validate and deploy
./deploy-simple.sh

# Or deploy via Railway
git push origin main  # Triggers automatic Railway deployment
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AnythingLLM   â”‚â”€â”€â”€â–¶â”‚  Simplified API  â”‚â”€â”€â”€â–¶â”‚  Tilores Data   â”‚
â”‚      (UI)       â”‚    â”‚   (/chat/invoke) â”‚    â”‚  (310+ fields)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   LangSmith     â”‚
                       â”‚   (Tracing)     â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š LangSmith Framework - 7 Core Models with Multi-Spectrum Data Experimentation

### ğŸ¯ **Primary LangSmith Framework Models (310+ Tilores Fields Integration)**

**Performance Data from Live LangSmith Experiments:**

| Rank | Model ID (OpenAI Endpoint) | Provider | Response Time | Context Limit | Quality Score | Status |
|------|----------------------------|----------|---------------|---------------|---------------|--------|
| 1 | `gemini-1.5-flash-002` | Google | **~3.1s** | 1M tokens | 95%+ | âœ… **FASTEST** |
| 2 | `claude-3-haiku` | Anthropic | **~4.0s** | 200K tokens | 92%+ | âœ… Working |
| 3 | `llama-3.3-70b-versatile` | Groq | **~5.1s** | 32K tokens | 90%+ | âœ… Working |
| 4 | `gpt-4o-mini` | OpenAI | **~7.4s** | 128K tokens | 94%+ | âœ… Working |
| 5 | `deepseek-r1-distill-llama-70b` | Groq | **~8.7s** | 32K tokens | 89%+ | âœ… Working |
| 6 | `gemini-2.5-flash` | Google | **~7.2s** | 2M tokens | 96%+ | âœ… **NEW** |
| 7 | `gemini-2.5-flash-lite` | Google | **~3.5s** | 1M tokens | 93%+ | âœ… **NEW** |

### ğŸ§  **4-Phase Virtuous Cycle AI Improvement Methodology**

**ğŸ”„ Automated Continuous Improvement System:**
- **Quality Target**: 90%+ achievement across all 7 models and 7 data spectrums
- **Self-Healing**: Automated quality monitoring with real-time optimization
- **Learning Accumulation**: AI learns from each optimization cycle
- **Production Integration**: Safe deployment with rollback capabilities

#### **Phase 1: Multi-Spectrum Foundation**
- **7 Models Ã— 7 Spectrums**: 49 baseline combinations tested
- **Real Customer Data**: Edwina Hawthorne validation (blessedwina@aol.com, Client ID: 2270)
- **Quality Metrics**: Comprehensive scoring across accuracy, speed, completeness
- **Statistical Analysis**: Trend analysis with numpy fallback for environment compatibility

#### **Phase 2: AI Prompt Optimization**
- **Pattern Analysis**: Automated identification of high-performing prompt patterns
- **AI-Driven Refinement**: LangChain integration for intelligent prompt optimization
- **A/B Testing**: Statistical significance testing across all model-spectrum combinations
- **Model-Specific Strategies**: Tailored optimization approaches for each model

#### **Phase 3: Continuous Improvement**
- **Quality Monitoring**: Real-time 90% threshold detection with automated alerting
- **Learning Accumulation**: Persistent learning patterns across optimization cycles
- **Self-Healing**: Automated quality degradation response and optimization
- **Deployment Automation**: Intelligent deployment decisions with rollback capabilities

#### **Phase 4: Production Integration**
- **Safe Deployment**: Backup and rollback mechanisms for production prompts
- **Railway Integration**: Production environment compatibility and monitoring
- **A/B Testing**: Production A/B testing infrastructure with traffic splitting
- **Performance Monitoring**: Real-time metrics collection across all models and spectrums

**ğŸ¯ Automatic Features:**
- **Quality Degradation Detection**: Automatically triggers optimization when quality drops below 90%
- **Pattern Learning**: AI learns successful optimization patterns and applies them automatically
- **Self-Improving Prompts**: System prompts continuously optimize based on performance data
- **Production Safety**: All optimizations validated before deployment with automatic rollback

### ğŸ”¬ **Multi-Spectrum Data Experimentation Framework**

**7 Data Spectrums with 310+ Tilores Fields Integration:**

1. **Customer Identity Spectrum** - Core identification fields (name, email, phone, client_id)
2. **Financial Profile Spectrum** - Credit scores, payment history, financial metrics
3. **Contact Information Spectrum** - Addresses, phone numbers, communication preferences
4. **Transaction History Spectrum** - Payment records, transaction patterns, account activity
5. **Relationship Mapping Spectrum** - Entity relationships, family connections, business links
6. **Risk Assessment Spectrum** - Credit risk, fraud indicators, compliance flags
7. **Behavioral Analytics Spectrum** - Usage patterns, interaction history, preferences

**Framework Capabilities:**
- **Real-time Quality Metrics**: Continuous monitoring of response accuracy and relevance
- **Statistical Analysis**: Trend analysis with numpy fallback for environment compatibility
- **Automated Optimization**: AI-driven prompt refinement based on performance data
- **Cross-Spectrum Validation**: Ensuring consistency across all data dimensions

### âš ï¸ **Recently Deprecated/Removed Models**

| Model ID (OpenAI Endpoint) | Provider | Issue | Status | Replacement |
|----------------------------|----------|-------|--------|-------------|
| `gpt-3.5-turbo` | OpenAI | Context limit exceeded (16K) | âŒ **REMOVED** | Use `gpt-4o-mini` (128K context) |
| `llama-3.3-70b-specdec` | Groq | Decommissioned by provider | âŒ **DEPRECATED** | Use `llama-3.3-70b-versatile` |
| `mixtral-8x7b-32768` | Groq | Decommissioned by provider | âŒ **DEPRECATED** | Use `llama-3.3-70b-versatile` |
| `llama-3.2-90b-text-preview` | Groq | Decommissioned by provider | âŒ **DEPRECATED** | Use `deepseek-r1-distill-llama-70b` |

### ğŸ§  **High-Quality Models**

| Model ID (OpenAI Endpoint) | Provider | Speed | Use Case | Status |
|----------------------------|----------|-------|----------|--------|
| `gpt-5-mini` | OpenAI | **Latest** | Advanced reasoning, latest features | âœ… Working |
| `gpt-4o` | OpenAI | **2.789s avg** | Complex analysis, high accuracy | âœ… Working |
| `gpt-4o-mini` | OpenAI | **1.915s avg** | Balanced speed/quality | âœ… Working |
| `gpt-4.1-mini` | OpenAI | **Fallback** | Reliable baseline | âœ… Working |
| `gpt-3.5-turbo` | OpenAI | **1.016s avg** | Fast, cost-effective | âœ… Working |

### ğŸ­ **Specialized Models**

| Model ID (OpenAI Endpoint) | Provider | Speed | Use Case | Status |
|----------------------------|----------|-------|----------|--------|
| `claude-3-sonnet` | Anthropic | **Advanced** | Complex reasoning, analysis | âœ… Working |
| `claude-3-haiku` | Anthropic | **Fast** | Quick responses, simple tasks | âœ… Working |
| `gemini-1.5-flash-002` | Google | **2.3s avg** | Speed-critical queries | âœ… Working |
| `gemini-2.5-flash` | Google | **7.2s avg** | Enhanced reasoning, complex analysis | âœ… Working |
| `gemini-2.5-flash-lite` | Google | **3.5s avg** | Balanced speed/quality | âœ… Working |

### ğŸŒ **OpenRouter/Cerebras Models**

| Model ID (OpenAI Endpoint) | Provider | Speed | Use Case | Status |
|----------------------------|----------|-------|----------|--------|
| `llama-3.3-70b-versatile-openrouter` | OpenRouter/Cerebras | **2-4x faster** | Ultra-fast inference | âœ… Working |
| `qwen-3-32b-openrouter` | OpenRouter/Cerebras | **Ultra-fast** | Efficient reasoning | âœ… Working |

### ğŸ¯ **Model Selection Guide**

**For Speed-Critical Applications (< 3s):**
- Primary: `gemini-1.5-flash-002` (~2.3s avg) - Fastest overall
- Backup: `llama-3.3-70b-versatile` (~5.1s avg)

**For Balanced Performance:**
- Primary: `gemini-2.5-flash-lite` (~3.5s avg) - Best speed/quality balance
- Backup: `gpt-4o-mini` (~7.4s avg, large context)

**For Complex Analysis:**
- Primary: `gemini-2.5-flash` (~7.2s avg) - Enhanced reasoning
- Backup: `claude-3-sonnet` (advanced reasoning)

**For Phone Applications (< 10s response):**
- Primary: `gemini-2.5-flash-lite` (~3.5s avg)
- Backup: `llama-3.3-70b-versatile` (~5.1s avg)

**For Cost Optimization:**
- Primary: `deepseek-r1-distill-llama-70b` (~8.7s avg)
- Backup: `gemini-1.5-flash-002` (~2.3s avg)

### ğŸ“¡ **OpenAI API Compatibility**

All models are accessible via standard OpenAI API format:

```bash
curl -X POST https://tiloresx-production.up.railway.app/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama-3.3-70b-versatile",
    "messages": [{"role": "user", "content": "Hello"}],
    "max_tokens": 100
  }'
```

**Available Endpoints:**
- `/v1/models` - List all available models
- `/v1/chat/completions` - OpenAI-compatible chat completions
- `/health` - Service health check
- `/metrics` - Performance monitoring

---

## ğŸ“š Related Documentation

### Project Context & Background
- **[Project Overview](memory-bank/tilores_X_memory_bank_project-overview.md)** - What Tilores_X is and its relationship to legacy systems
- **[Project Status](memory-bank/tilores_X_memory_bank_project-status.md)** - Current development status and achievements
- **[Architecture Documentation](memory-bank/tilores_X_memory_bank_architecture_README.md)** - Detailed technical architecture and components

### Development & Operations
- **[Setup Guide](memory-bank/tilores_X_memory_bank_SETUP_GUIDE.md)** - Complete environment setup and configuration
- **[Migration Guide](memory-bank/tilores_X_memory_bank_migration-from-legacy.md)** - Transitioning from legacy Tilores-Jul10
- **[Decision Records](memory-bank/tilores_X_memory_bank_decisions_README.md)** - Architectural decisions and rationale

### Development Tracking
- **[Development Log](memory-bank/tilores_X_memory_bank_updates_development-log.md)** - Ongoing development progress
- **[Status Reports](memory-bank/tilores_X_memory_bank_status-reports_README.md)** - Regular project status updates

---

## ğŸš€ Production Status

âœ… **Ready for Production**: Simplified, tested, and optimized for AnythingLLM
âœ… **Clean Codebase**: Removed obsolete components and complexity
âœ… **Performance Optimized**: Focus on core functionality
âœ… **AnythingLLM Compatible**: Direct integration via `/chat/invoke`
âœ… **Monitoring Ready**: LangSmith tracing active

*For detailed component information and system design, see [Architecture Documentation](memory-bank/tilores_X_memory_bank_architecture_README.md)*

---

**Ready for immediate deployment and AnythingLLM integration!**
