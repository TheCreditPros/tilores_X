# Tilores Simplified API for AnythingLLM Integration

ğŸš€ **Production-Ready Simplified Tilores API with AnythingLLM Compatibility**

## ğŸŒ Production Access

**ğŸ”— Production API**: https://tiloresx-production.up.railway.app
**ğŸ’¬ UI Interface**: AnythingLLM (anythingllm.thecreditpros.com)

**ğŸ“Š Key Endpoints**:
- **Health Check**: `/health`
- **OpenAI API**: `/v1/chat/completions` (OpenAI compatible)
- **Models List**: `/v1/models`
- **Metrics**: `/metrics`
- **Detailed Health**: `/health/detailed`

---

## ğŸ¯ Simplified Architecture

This API has been streamlined for optimal performance with AnythingLLM:

### **Core Features:**
- âœ… **LangServe Integration**: Direct `/chat/invoke` endpoint for AnythingLLM
- âœ… **Tilores Customer Data**: Complete access to 310+ customer fields
- âœ… **Multi-Provider Models**: OpenAI, Groq, Anthropic, Google AI support
- âœ… **LangSmith Tracing**: Complete conversation monitoring
- âœ… **Credit Reports**: Comprehensive credit data integration
- âœ… **Clean Architecture**: Minimal, focused codebase

### **Removed Complexity:**
- âŒ Multiple playground interfaces (use AnythingLLM instead)
- âŒ Complex agent implementations
- âŒ Redundant test infrastructure
- âŒ Excessive deployment machinery

---

## ğŸš€ Quick Start

### Local Development
```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Configure environment (copy from .env.example)
cp .env .env.local
# Edit .env.local with your API keys

# 3. Start server
python main_enhanced.py
# Server runs on http://localhost:8000
```

### AnythingLLM Integration
```bash
# Configure AnythingLLM to use:
# API Base: http://localhost:8000 (local) or production URL
# Endpoint: /chat/invoke
# Model: gpt-4o-mini, llama-3.3-70b-versatile, etc.
```

---

## ğŸ“‹ API Usage

### Health Check
```bash
curl https://tiloresx-production.up.railway.app/health
```

### Customer Search via AnythingLLM
Simply ask in AnythingLLM:
- "Find customer with client ID 1648647"
- "Get credit report for Dawn Bruton"
- "What is customer 1881899's email address?"

### Direct API Call
```bash
curl -X POST https://tiloresx-production.up.railway.app/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama-3.3-70b-versatile",
    "messages": [{"role": "user", "content": "Find customer with client ID 1648647"}],
    "max_tokens": 500
  }'
```

---

## ğŸ”§ Development & Testing

### Run Tests
```bash
# Simple test suite
python test_simplified_runner.py

# Pre-commit validation
./scripts/test/pre_commit_validation.sh
```

### Deployment
```bash
# Validate and deploy
./deploy-simple.sh
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AnythingLLM   â”‚â”€â”€â”€â–¶â”‚  Simplified API  â”‚â”€â”€â”€â–¶â”‚  Tilores Data   â”‚
â”‚      (UI)       â”‚    â”‚   (/chat/invoke) â”‚    â”‚  (310+ fields)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   LangSmith     â”‚
                       â”‚   (Tracing)     â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Supported Models & Performance

### ğŸï¸ **Ultra-Fast Models (Recommended for Production)**

| Model ID (OpenAI Endpoint) | Provider | Speed | Use Case | Status |
|----------------------------|----------|-------|----------|--------|
| `llama-3.3-70b-versatile` | Groq | **~600ms avg** | General purpose, fast responses | âœ… Working |
| `deepseek-r1-distill-llama-70b` | Groq | **~3.5s avg** | Cost-effective reasoning | âœ… Working |

### âš ï¸ **Recently Deprecated Models**

| Model ID (OpenAI Endpoint) | Provider | Previous Speed | Status | Replacement |
|----------------------------|----------|----------------|--------|-------------|
| `llama-3.3-70b-specdec` | Groq | 1,665 tok/s | âŒ **DEPRECATED** | Use `llama-3.3-70b-versatile` |
| `mixtral-8x7b-32768` | Groq | 500+ tok/s | âŒ **DEPRECATED** | Use `llama-3.3-70b-versatile` |
| `llama-3.2-90b-text-preview` | Groq | 330 tok/s | âŒ **DEPRECATED** | Use `deepseek-r1-distill-llama-70b` |

### ğŸ§  **High-Quality Models**

| Model ID (OpenAI Endpoint) | Provider | Speed | Use Case | Status |
|----------------------------|----------|-------|----------|--------|
| `gpt-5-mini` | OpenAI | **Latest** | Advanced reasoning, latest features | âœ… Working |
| `gpt-4o` | OpenAI | **2.789s avg** | Complex analysis, high accuracy | âœ… Working |
| `gpt-4o-mini` | OpenAI | **1.915s avg** | Balanced speed/quality | âœ… Working |
| `gpt-4.1-mini` | OpenAI | **Fallback** | Reliable baseline | âœ… Working |
| `gpt-3.5-turbo` | OpenAI | **1.016s avg** | Fast, cost-effective | âœ… Working |

### ğŸ­ **Specialized Models**

| Model ID (OpenAI Endpoint) | Provider | Speed | Use Case | Status |
|----------------------------|----------|-------|----------|--------|
| `claude-3-sonnet` | Anthropic | **Advanced** | Complex reasoning, analysis | âœ… Working |
| `claude-3-haiku` | Anthropic | **Fast** | Quick responses, simple tasks | âœ… Working |
| `gemini-1.5-flash-002` | Google | **2.2s avg** | Multimodal, fast processing | âœ… Working |

### ğŸŒ **OpenRouter/Cerebras Models**

| Model ID (OpenAI Endpoint) | Provider | Speed | Use Case | Status |
|----------------------------|----------|-------|----------|--------|
| `llama-3.3-70b-versatile-openrouter` | OpenRouter/Cerebras | **2-4x faster** | Ultra-fast inference | âœ… Working |
| `qwen-3-32b-openrouter` | OpenRouter/Cerebras | **Ultra-fast** | Efficient reasoning | âœ… Working |

### ğŸ¯ **Model Selection Guide**

**For Phone Applications (< 2s response):**
- Primary: `llama-3.3-70b-versatile` (~600ms avg)
- Backup: `gpt-4o-mini` (1.915s avg)

**For General Chat:**
- Primary: `llama-3.3-70b-versatile` (~600ms avg)
- Backup: `gpt-3.5-turbo` (1.016s avg)

**For Complex Analysis:**
- Primary: `claude-3-sonnet` (advanced reasoning)
- Backup: `gpt-4o` (2.789s avg)

**For Cost Optimization:**
- Primary: `deepseek-r1-distill-llama-70b` (~3.5s avg)
- Backup: `gpt-3.5-turbo` (1.016s avg)

### ğŸ“¡ **OpenAI API Compatibility**

All models are accessible via standard OpenAI API format:

```bash
curl -X POST https://tiloresx-production.up.railway.app/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama-3.3-70b-versatile",
    "messages": [{"role": "user", "content": "Hello"}],
    "max_tokens": 100
  }'
```

**Available Endpoints:**
- `/v1/models` - List all available models
- `/v1/chat/completions` - OpenAI-compatible chat completions
- `/health` - Service health check
- `/metrics` - Performance monitoring

---

## ğŸ“š Related Documentation

### Project Context & Background
- **[Project Overview](memory-bank/tilores_X_memory_bank_project-overview.md)** - What Tilores_X is and its relationship to legacy systems
- **[Project Status](memory-bank/tilores_X_memory_bank_project-status.md)** - Current development status and achievements
- **[Architecture Documentation](memory-bank/tilores_X_memory_bank_architecture_README.md)** - Detailed technical architecture and components

### Development & Operations
- **[Setup Guide](memory-bank/tilores_X_memory_bank_SETUP_GUIDE.md)** - Complete environment setup and configuration
- **[Migration Guide](memory-bank/tilores_X_memory_bank_migration-from-legacy.md)** - Transitioning from legacy Tilores-Jul10
- **[Decision Records](memory-bank/tilores_X_memory_bank_decisions_README.md)** - Architectural decisions and rationale

### Development Tracking
- **[Development Log](memory-bank/tilores_X_memory_bank_updates_development-log.md)** - Ongoing development progress
- **[Status Reports](memory-bank/tilores_X_memory_bank_status-reports_README.md)** - Regular project status updates

---

## ğŸš€ Production Status

âœ… **Ready for Production**: Simplified, tested, and optimized for AnythingLLM
âœ… **Clean Codebase**: Removed obsolete components and complexity
âœ… **Performance Optimized**: Focus on core functionality
âœ… **AnythingLLM Compatible**: Direct integration via `/chat/invoke`
âœ… **Monitoring Ready**: LangSmith tracing active

*For detailed component information and system design, see [Architecture Documentation](memory-bank/tilores_X_memory_bank_architecture_README.md)*

---

**Ready for immediate deployment and AnythingLLM integration!**
