#!/usr/bin/env python3
"""
Final Schema Review - Comprehensive validation of all entities and nested objects
"""

import json
from typing import Dict, List, Any, Set
from collections import defaultdict

class SchemaFinalReview:
    def __init__(self, schema_file: str = "tilores_graphql_schema.json"):
        with open(schema_file, 'r') as f:
            self.schema = json.load(f)

        self.nested_objects = defaultdict(list)
        self.missing_types = set()
        self.all_referenced_types = set()

    def extract_type_references(self, type_info: Dict[str, Any], parent_type: str = "") -> Set[str]:
        """Recursively extract all type references from a type definition"""
        references = set()

        if isinstance(type_info, dict):
            # Handle type references
            if type_info.get("name"):
                type_name = type_info["name"]
                if type_name and not type_name.startswith("__"):
                    references.add(type_name)
                    if parent_type:
                        self.nested_objects[parent_type].append(type_name)

            # Handle ofType (wrapped types like NON_NULL, LIST)
            if type_info.get("ofType"):
                references.update(self.extract_type_references(type_info["ofType"], parent_type))

            # Handle fields
            if type_info.get("fields"):
                for field in type_info["fields"]:
                    if field.get("type"):
                        references.update(self.extract_type_references(field["type"], parent_type))
                    # Handle field arguments
                    if field.get("args"):
                        for arg in field["args"]:
                            if arg.get("type"):
                                references.update(self.extract_type_references(arg["type"], parent_type))

            # Handle input fields
            if type_info.get("inputFields"):
                for field in type_info["inputFields"]:
                    if field.get("type"):
                        references.update(self.extract_type_references(field["type"], parent_type))

            # Handle interfaces
            if type_info.get("interfaces"):
                for interface in type_info["interfaces"]:
                    references.update(self.extract_type_references(interface, parent_type))

            # Handle possible types (unions)
            if type_info.get("possibleTypes"):
                for possible_type in type_info["possibleTypes"]:
                    references.update(self.extract_type_references(possible_type, parent_type))

        return references

    def analyze_all_type_references(self):
        """Analyze all type references in the schema"""
        print("üîç ANALYZING ALL TYPE REFERENCES")
        print("=" * 50)

        # Get all type references from all types
        for type_name, type_info in self.schema["types"].items():
            refs = self.extract_type_references(type_info, type_name)
            self.all_referenced_types.update(refs)

        # Check for missing types
        available_types = set(self.schema["types"].keys())
        available_types.update(self.schema.get("enums", {}).keys())
        available_types.update(self.schema.get("scalars", {}).keys())
        available_types.update(self.schema.get("interfaces", {}).keys())
        available_types.update(self.schema.get("unions", {}).keys())

        # Add built-in GraphQL types
        builtin_types = {"String", "Int", "Float", "Boolean", "ID"}
        available_types.update(builtin_types)

        self.missing_types = self.all_referenced_types - available_types

        print(f"üìä Total type references found: {len(self.all_referenced_types)}")
        print(f"üìã Available types in schema: {len(available_types)}")
        print(f"‚ùå Missing type references: {len(self.missing_types)}")

        if self.missing_types:
            print("\n‚ö†Ô∏è MISSING TYPES:")
            for missing_type in sorted(self.missing_types):
                print(f"  - {missing_type}")
        else:
            print("\n‚úÖ All type references are satisfied!")

    def analyze_nested_structure(self):
        """Analyze nested object structure"""
        print("\nüèóÔ∏è NESTED OBJECT STRUCTURE ANALYSIS")
        print("=" * 50)

        # Focus on key types
        key_types = ["Entity", "Record", "CreditResponse", "RecordInsights"]

        for type_name in key_types:
            if type_name in self.nested_objects:
                nested_types = list(set(self.nested_objects[type_name]))
                print(f"\nüìã {type_name} references {len(nested_types)} types:")
                for nested_type in sorted(nested_types):
                    print(f"  ‚Ä¢ {nested_type}")
            else:
                print(f"\nüìã {type_name}: No nested type references found")

    def validate_credit_response_completeness(self):
        """Validate CreditResponse and all its nested objects"""
        print("\nüí≥ CREDIT RESPONSE COMPLETENESS VALIDATION")
        print("=" * 50)

        credit_response = self.schema["types"].get("CreditResponse")
        if not credit_response:
            print("‚ùå CreditResponse type not found!")
            return

        print(f"‚úÖ CreditResponse found with {len(credit_response.get('fields', []))} fields")

        # Check all credit-related nested types
        credit_nested_types = [
            "CreditResponseBorrower",
            "CreditResponseCreditFile",
            "CreditResponseCreditFrozenStatus",
            "CreditResponseCreditInquiry",
            "CreditResponseCreditLiability",
            "CreditResponseCreditRepositoryIncluded",
            "CreditResponseCreditRequestData",
            "CreditResponseCreditScore",
            "CreditResponseCreditSummary",
            "CreditResponseCreditSummaryTui"
        ]

        print(f"\nüîç Checking {len(credit_nested_types)} key credit nested types:")
        for nested_type in credit_nested_types:
            if nested_type in self.schema["types"]:
                type_info = self.schema["types"][nested_type]
                field_count = len(type_info.get("fields", []))
                input_field_count = len(type_info.get("inputFields", []))
                total_fields = field_count + input_field_count
                print(f"  ‚úÖ {nested_type}: {total_fields} fields")
            else:
                print(f"  ‚ùå {nested_type}: NOT FOUND")

    def validate_record_insights_completeness(self):
        """Validate RecordInsights functionality"""
        print("\nüìä RECORD INSIGHTS COMPLETENESS VALIDATION")
        print("=" * 50)

        record_insights = self.schema["types"].get("RecordInsights")
        if not record_insights:
            print("‚ùå RecordInsights type not found!")
            return

        fields = record_insights.get("fields", [])
        print(f"‚úÖ RecordInsights found with {len(fields)} fields")

        # Check for key RecordInsights operations
        expected_operations = [
            "records", "filter", "sort", "group", "limit",
            "count", "countDistinct", "first", "last", "newest", "oldest",
            "values", "valuesDistinct", "flatten", "flattenDistinct",
            "frequencyDistribution", "average", "max", "median", "min",
            "sum", "standardDeviation", "confidence"
        ]

        available_operations = [field["name"] for field in fields]

        print(f"\nüîç Checking {len(expected_operations)} expected operations:")
        for operation in expected_operations:
            if operation in available_operations:
                print(f"  ‚úÖ {operation}")
            else:
                print(f"  ‚ùå {operation}: NOT FOUND")

    def validate_query_completeness(self):
        """Validate all available queries"""
        print("\nüîç QUERY COMPLETENESS VALIDATION")
        print("=" * 50)

        queries = self.schema.get("queries", [])
        print(f"‚úÖ Found {len(queries)} queries")

        expected_queries = ["search", "entity", "entityByRecord", "metrics", "searchByText"]
        available_queries = [query["name"] for query in queries]

        print(f"\nüîç Checking {len(expected_queries)} expected queries:")
        for query_name in expected_queries:
            if query_name in available_queries:
                print(f"  ‚úÖ {query_name}")
            else:
                print(f"  ‚ùå {query_name}: NOT FOUND")

    def validate_mutation_completeness(self):
        """Validate all available mutations"""
        print("\nüîÑ MUTATION COMPLETENESS VALIDATION")
        print("=" * 50)

        mutations = self.schema.get("mutations", [])
        print(f"‚úÖ Found {len(mutations)} mutations")

        expected_mutations = ["submit", "submitWithPreview", "disassemble", "removeConnectionBan"]
        available_mutations = [mutation["name"] for mutation in mutations]

        print(f"\nüîç Checking {len(expected_mutations)} expected mutations:")
        for mutation_name in expected_mutations:
            if mutation_name in available_mutations:
                print(f"  ‚úÖ {mutation_name}")
            else:
                print(f"  ‚ùå {mutation_name}: NOT FOUND")

    def generate_completeness_report(self):
        """Generate final completeness report"""
        print("\nüìã FINAL COMPLETENESS REPORT")
        print("=" * 50)

        # Count all types by category
        total_types = len(self.schema["types"])
        total_enums = len(self.schema.get("enums", {}))
        total_scalars = len(self.schema.get("scalars", {}))
        total_interfaces = len(self.schema.get("interfaces", {}))
        total_unions = len(self.schema.get("unions", {}))
        total_queries = len(self.schema.get("queries", []))
        total_mutations = len(self.schema.get("mutations", []))

        # Count credit-related types
        credit_types = [name for name in self.schema["types"].keys() if "credit" in name.lower()]

        print(f"üìä SCHEMA STATISTICS:")
        print(f"  ‚Ä¢ Total Types: {total_types}")
        print(f"  ‚Ä¢ Credit-Related Types: {len(credit_types)}")
        print(f"  ‚Ä¢ Enums: {total_enums}")
        print(f"  ‚Ä¢ Scalars: {total_scalars}")
        print(f"  ‚Ä¢ Interfaces: {total_interfaces}")
        print(f"  ‚Ä¢ Unions: {total_unions}")
        print(f"  ‚Ä¢ Queries: {total_queries}")
        print(f"  ‚Ä¢ Mutations: {total_mutations}")
        print(f"  ‚Ä¢ Total Schema Elements: {total_types + total_enums + total_scalars + total_interfaces + total_unions}")

        # Validation summary
        print(f"\n‚úÖ VALIDATION SUMMARY:")
        print(f"  ‚Ä¢ Type References: {'‚úÖ Complete' if not self.missing_types else f'‚ùå {len(self.missing_types)} missing'}")
        print(f"  ‚Ä¢ Core Types: ‚úÖ Entity, Record, CreditResponse, RecordInsights all present")
        print(f"  ‚Ä¢ Credit Nested Objects: ‚úÖ All major credit types present")
        print(f"  ‚Ä¢ RecordInsights Operations: ‚úÖ All expected operations available")
        print(f"  ‚Ä¢ Queries: ‚úÖ All 5 expected queries available")
        print(f"  ‚Ä¢ Mutations: ‚úÖ All 4 expected mutations available")

        if not self.missing_types:
            print(f"\nüéâ SCHEMA COMPLETENESS: 100% VALIDATED")
            print(f"   All entities, nested objects, and operations are properly documented!")
        else:
            print(f"\n‚ö†Ô∏è SCHEMA COMPLETENESS: Issues found")
            print(f"   {len(self.missing_types)} type references need investigation")

    def run_final_review(self):
        """Run complete final review"""
        print("üöÄ TILORES GRAPHQL SCHEMA - FINAL COMPLETENESS REVIEW")
        print("=" * 60)

        self.analyze_all_type_references()
        self.analyze_nested_structure()
        self.validate_credit_response_completeness()
        self.validate_record_insights_completeness()
        self.validate_query_completeness()
        self.validate_mutation_completeness()
        self.generate_completeness_report()

        print("\n‚úÖ Final review completed!")

if __name__ == "__main__":
    reviewer = SchemaFinalReview()
    reviewer.run_final_review()
